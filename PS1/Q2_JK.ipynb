{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55301984-86bc-4613-9e60-e3eaae93d857",
   "metadata": {},
   "source": [
    "# Question 2 (BLP)\n",
    "\n",
    "We assume the demand model $$u_{ijt} = X_{jt}\\beta + \\sigma_{B}\\nu_{i} + \\alpha p_{jt} + \\sigma_{I}I_{i}p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$ and use BLP to estimate it. The steps are detailed below:\n",
    "\n",
    "## Step 1: Simulate draws\n",
    "\n",
    "The logit specification of our model implies that our shares can be written as an integral of fractions of utility components. Specifically, we can adapt the formulas from class to our model: $$s_{jt} = \\int \\frac{X_{jt}\\beta + \\sigma_{B}\\nu_{i} + \\alpha p_{jt} + \\sigma_{I}I_{it}p_{jt} + \\xi_{jt}}{1+\\sum_{m=1}^{J}X_{mt}\\beta + \\sigma_{B}\\nu_{i} + \\alpha p_{mt} + \\sigma_{I}I_{it}p_{mt} + \\xi_{mt}}dP_{I}(I)dP_{\\nu}(\\nu)$$ \n",
    "While this integral cannot be solved analytically, we can simulate random draws of income (uniformly over the income data we have for each product-market) and normal demand shocks to estimate shares conditional on demand parameters:\n",
    "$$\\hat{s}_{jt} = \\sum_{r}\\frac{X_{jt}\\beta + \\sigma_{B}\\nu_{r} + \\alpha p_{jt} + \\sigma_{I}I_{rt}p_{jt} + \\xi_{jt}}{1+\\sum_{m=1}^{J}X_{mt}\\beta + \\sigma_{B}\\nu_{r} + \\alpha p_{mt} + \\sigma_{I}I_{rt}p_{mt} + \\xi_{mt}}$$\n",
    "We code a function that returns this share while taking demand parameters as input below.\n",
    "\n",
    "To get closer to the notation used in the lecture notes ($\\beta$ is used differently in the problem set,) we will express the deterministic component of utility as $\\delta_{jt}$ = $X_{jt}\\beta + \\alpha p_{jt} + \\xi_{jt}$ and the variables that interact with the idiosyncratic components as $\\sigma = (\\sigma_{B},\\sigma_{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902fa90f-8c37-4b51-8c44-174554698bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>rev</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>hhincome11</th>\n",
       "      <th>hhincome12</th>\n",
       "      <th>hhincome13</th>\n",
       "      <th>hhincome14</th>\n",
       "      <th>hhincome15</th>\n",
       "      <th>hhincome16</th>\n",
       "      <th>hhincome17</th>\n",
       "      <th>hhincome18</th>\n",
       "      <th>hhincome19</th>\n",
       "      <th>hhincome20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>52.64</td>\n",
       "      <td>32.96</td>\n",
       "      <td>...</td>\n",
       "      <td>9.629704</td>\n",
       "      <td>12.109250</td>\n",
       "      <td>12.435180</td>\n",
       "      <td>11.096550</td>\n",
       "      <td>9.074136</td>\n",
       "      <td>11.56383</td>\n",
       "      <td>10.475980</td>\n",
       "      <td>11.31761</td>\n",
       "      <td>10.95628</td>\n",
       "      <td>10.73356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>39.24</td>\n",
       "      <td>24.48</td>\n",
       "      <td>...</td>\n",
       "      <td>9.627645</td>\n",
       "      <td>9.719968</td>\n",
       "      <td>11.206970</td>\n",
       "      <td>10.461870</td>\n",
       "      <td>10.513160</td>\n",
       "      <td>11.65730</td>\n",
       "      <td>8.476680</td>\n",
       "      <td>11.32159</td>\n",
       "      <td>10.28266</td>\n",
       "      <td>10.02471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>20.22</td>\n",
       "      <td>12.90</td>\n",
       "      <td>...</td>\n",
       "      <td>10.185430</td>\n",
       "      <td>10.272690</td>\n",
       "      <td>10.556770</td>\n",
       "      <td>8.676463</td>\n",
       "      <td>10.341440</td>\n",
       "      <td>11.64640</td>\n",
       "      <td>9.590904</td>\n",
       "      <td>11.96942</td>\n",
       "      <td>11.36072</td>\n",
       "      <td>11.35747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>39.60</td>\n",
       "      <td>24.84</td>\n",
       "      <td>...</td>\n",
       "      <td>11.982770</td>\n",
       "      <td>8.499218</td>\n",
       "      <td>8.030489</td>\n",
       "      <td>11.080500</td>\n",
       "      <td>8.894314</td>\n",
       "      <td>10.27435</td>\n",
       "      <td>11.675790</td>\n",
       "      <td>12.48191</td>\n",
       "      <td>10.79339</td>\n",
       "      <td>11.42795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>33.40</td>\n",
       "      <td>21.20</td>\n",
       "      <td>...</td>\n",
       "      <td>9.367624</td>\n",
       "      <td>9.109353</td>\n",
       "      <td>10.237140</td>\n",
       "      <td>11.982330</td>\n",
       "      <td>10.211610</td>\n",
       "      <td>10.33920</td>\n",
       "      <td>11.067370</td>\n",
       "      <td>11.89204</td>\n",
       "      <td>10.28755</td>\n",
       "      <td>11.68925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_    rev  total_cost  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06  52.64       32.96   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04  39.24       24.48   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15  20.22       12.90   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07  39.60       24.84   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12  33.40       21.20   \n",
       "\n",
       "   ...  hhincome11  hhincome12  hhincome13  hhincome14  hhincome15  \\\n",
       "0  ...    9.629704   12.109250   12.435180   11.096550    9.074136   \n",
       "1  ...    9.627645    9.719968   11.206970   10.461870   10.513160   \n",
       "2  ...   10.185430   10.272690   10.556770    8.676463   10.341440   \n",
       "3  ...   11.982770    8.499218    8.030489   11.080500    8.894314   \n",
       "4  ...    9.367624    9.109353   10.237140   11.982330   10.211610   \n",
       "\n",
       "   hhincome16  hhincome17  hhincome18  hhincome19  hhincome20  \n",
       "0    11.56383   10.475980    11.31761    10.95628    10.73356  \n",
       "1    11.65730    8.476680    11.32159    10.28266    10.02471  \n",
       "2    11.64640    9.590904    11.96942    11.36072    11.35747  \n",
       "3    10.27435   11.675790    12.48191    10.79339    11.42795  \n",
       "4    10.33920   11.067370    11.89204    10.28755    11.68925  \n",
       "\n",
       "[5 rows x 849 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('./cleaned_data/data.csv')\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "\n",
    "demo = pd.read_csv('./PS1_Data/OTCDemographics.csv',sep='\\t')\n",
    "data = pd.merge(data,demo,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607eb459-80b8-49d3-92bc-9f5ace778f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "R = 100\n",
    "\n",
    "# Simulate an individual draw in a single market: each row is a jt-level entry\n",
    "# Assumes delta is already calculated\n",
    "def calc_V(row,sigma_B,sigma_I,nu,hh):\n",
    "    \n",
    "    return row['delta'] + sigma_B*nu + sigma_I*row['hhincome'+str(hh)]*row['price_']\n",
    "\n",
    "\n",
    "# Simulate draws R=100 times and average out shares\n",
    "def sim_shares(orig,sigma_B,sigma_I):\n",
    "\n",
    "    # Keep covariates and intermediate variables\n",
    "    master = orig[['store','week','brand','sales_','price_','prom_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11','hhincome1','hhincome2','hhincome3','hhincome4','hhincome5','hhincome6','hhincome7','hhincome8','hhincome9','hhincome10','hhincome11','hhincome12','hhincome13','hhincome14','hhincome15','hhincome16','hhincome17','hhincome18','hhincome19','hhincome20','delta','w_old','w_new','s0','count']]\n",
    "    # tot is total of all simulated shares\n",
    "    master['tot'] = 0\n",
    "\n",
    "    # Simulate draws\n",
    "    for i in range(R):\n",
    "        data_copy = master.copy()\n",
    "        \n",
    "        # Demand shock\n",
    "        nu = np.random.normal()\n",
    "        # Choose income randomly\n",
    "        hh = random.randint(1,20)\n",
    "        \n",
    "        # data_copy['V'] = data_copy.apply(calc_V,axis=1,args=(sigma_B,sigma_I,nu,hh))\n",
    "        data_copy['V'] = data_copy['delta'] + sigma_B*nu + sigma_I*data_copy['hhincome'+str(hh)]*data_copy['price_']\n",
    "        \n",
    "        # Use logit to calculate product shares in market\n",
    "        data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "        data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "        data_sum['sum'] = data_sum['sum'] + 1\n",
    "        data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        data_copy['s'] = data_copy['V']/data_copy['sum']\n",
    "        data_copy = data_copy[['store','week','brand','s']]\n",
    "\n",
    "        # Add this iteration to our total\n",
    "        master = pd.merge(master,data_copy,how='left',left_on=['store','week','brand'],right_on=['store','week','brand'],validate='1:1')\n",
    "        master['tot'] = master['tot'] + master['s']\n",
    "        master = master.drop(columns=['s'])\n",
    "\n",
    "    # Average share\n",
    "    master['tot'] = master['tot']/R\n",
    "    return master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d9bb2-00cc-47bd-abb8-cafbfa77eca8",
   "metadata": {},
   "source": [
    "## Step 2: Contraction Mapping\n",
    "\n",
    "Given $sigma_{B}, sigma_{I}$, we can iterate the contraction mapping in the lecture notes to approximate a value of $\\delta_{jt}$ for each product-market pair that results in a share close to the actual shares in the data. The equation we iterate to approximate $\\delta_{jt}$ is:\n",
    "$$\\exp(\\delta^{i+1}_{jt}) = \\exp(\\delta^{i}_{jt})\\frac{s_{jt}^{0}}{s_{jt}(\\delta^{i}_{jt},\\beta)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b33e505-8fe5-45d9-9f48-eb4d5c9d7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate actual shares in data to use in iteration\n",
    "def calc_initial_shares(orig):\n",
    "\n",
    "    # Sum sales\n",
    "    data_sum = orig.groupby(['store', 'week'],as_index=False)['sales_'].sum()\n",
    "    data_sum.rename(columns={'sales_':'sum'},inplace=True)\n",
    "\n",
    "    # Calculate initial shares\n",
    "    orig = pd.merge(orig,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "    orig['s0'] = orig['sales_']/orig['count']\n",
    "    orig['share0'] = 1 - (orig['sum']/orig['count'])\n",
    "    orig['init'] = np.log(orig['s0']/orig['share0'])\n",
    "    orig = orig.drop(columns=['sum','share0'])\n",
    "    return orig   \n",
    "\n",
    "\n",
    "# Calculate delta: deterministic component of jt-level utility\n",
    "def calc_delta(orig,sigma_B,sigma_I):\n",
    "    \n",
    "    # Calculate initial shares\n",
    "    orig = calc_initial_shares(orig)\n",
    "\n",
    "    # Initialize search values and threshold\n",
    "    epsilon = 0.1\n",
    "    orig['w_old'] = np.exp(orig['s0'])\n",
    "    orig['w_new'] = 0\n",
    "    count = 0\n",
    "\n",
    "    # Iterate contraction mapping until threshold is found\n",
    "    while True:\n",
    "        orig['delta'] = np.log(orig['w_old'])\n",
    "        orig = sim_shares(orig,sigma_B,sigma_I)\n",
    "        orig['w_new'] = orig['w_old']*orig['s0']/orig['tot']\n",
    "        if (np.log(orig['w_new'])-np.log(orig['w_old'])).abs().mean() < epsilon:\n",
    "            break\n",
    "        orig['w_old'] = orig['w_new']\n",
    "        count += 1\n",
    "\n",
    "    return np.log(orig['w_new']).to_numpy()\n",
    "\n",
    "# Calculate xi: our jt-level residual\n",
    "# Two parts: iterate contraction mapping, then subtract out linear terms given beta\n",
    "def calc_xi(orig,sigma_B,sigma_I,beta):\n",
    "\n",
    "    # Calculate delta\n",
    "    orig['delta'] = calc_delta(orig,sigma_B,sigma_I)    \n",
    "\n",
    "    # Calculate xi: take linear component out of delta\n",
    "    orig['xi'] = orig['delta'] - orig[['price_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11']].dot(beta)\n",
    "    return orig['xi'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c7330-4fd0-488d-8921-9ff8bf654ac0",
   "metadata": {},
   "source": [
    "Below I try to run the above code step by step. Keeping the mess so that you can see the (lack of) convergence: the outputted numbers are the difference between successive values of $\\delta_{jt}$, averaged over all jt-pairs. It looks like there's initial convergence, but eventually it starts to explode..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7129ec-8d12-4ca8-80b2-6fd8cc41bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l2/qgb9rd795r92jzsy94cy01080000gn/T/ipykernel_36814/998985169.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  master['tot'] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.489137223491835\n"
     ]
    }
   ],
   "source": [
    "beta = np.zeros(11)\n",
    "beta[0] = 1\n",
    "data = calc_initial_shares(data)\n",
    "epsilon = 0.1\n",
    "data['w_old'] = np.exp(data['s0'])\n",
    "data['w_new'] = 0\n",
    "\n",
    "data['delta'] = np.log(data['w_old'])\n",
    "data = sim_shares(data,1,1)\n",
    "data['w_new'] = data['w_old']*data['s0']/data['tot']\n",
    "print((np.log(data['w_new'])-np.log(data['w_old'])).abs().mean())\n",
    "data['w_old'] = data['w_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90bcac83-943d-4e8a-b7c6-11479516f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.467108212771038\n",
      "0.006557234470005088\n",
      "5.431883731156276\n",
      "0.006889672529256574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_old\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m sim_shares(data,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_old\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m((np\u001b[38;5;241m.\u001b[39mlog(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_new\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_old\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean())\n",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m, in \u001b[0;36msim_shares\u001b[0;34m(orig, sigma_B, sigma_I)\u001b[0m\n\u001b[1;32m     37\u001b[0m data_copy \u001b[38;5;241m=\u001b[39m data_copy[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Add this iteration to our total\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m master \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(master,data_copy,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m,left_on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m'\u001b[39m],right_on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m'\u001b[39m],validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1:1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m master[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtot\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m master[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtot\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m master[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     42\u001b[0m master \u001b[38;5;241m=\u001b[39m master\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:169\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    155\u001b[0m         left_df,\n\u001b[1;32m    156\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    170\u001b[0m         left_df,\n\u001b[1;32m    171\u001b[0m         right_df,\n\u001b[1;32m    172\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    173\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    174\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    175\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    176\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    177\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    178\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    179\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    180\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:810\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_validate_kwd(validate)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1604\u001b[0m, in \u001b[0;36m_MergeOperation._validate_validate_kwd\u001b[0;34m(self, validate)\u001b[0m\n\u001b[1;32m   1602\u001b[0m     left_unique \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_left\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1604\u001b[0m     left_unique \u001b[38;5;241m=\u001b[39m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_arrays(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[1;32m   1607\u001b[0m     right_unique \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_right\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/multi.py:531\u001b[0m, in \u001b[0;36mMultiIndex.from_arrays\u001b[0;34m(cls, arrays, sortorder, names)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arrays[i]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arrays[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall arrays must be same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 531\u001b[0m codes, levels \u001b[38;5;241m=\u001b[39m factorize_from_iterables(arrays)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m    533\u001b[0m     names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(arr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:3023\u001b[0m, in \u001b[0;36mfactorize_from_iterables\u001b[0;34m(iterables)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;66;03m# For consistency, it should return two empty lists.\u001b[39;00m\n\u001b[1;32m   3021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n\u001b[0;32m-> 3023\u001b[0m codes, categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(factorize_from_iterable(it) \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m iterables))\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(codes), \u001b[38;5;28mlist\u001b[39m(categories)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:3023\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;66;03m# For consistency, it should return two empty lists.\u001b[39;00m\n\u001b[1;32m   3021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n\u001b[0;32m-> 3023\u001b[0m codes, categories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(factorize_from_iterable(it) \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m iterables))\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(codes), \u001b[38;5;28mlist\u001b[39m(categories)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:2996\u001b[0m, in \u001b[0;36mfactorize_from_iterable\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2991\u001b[0m     codes \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcodes\n\u001b[1;32m   2992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2993\u001b[0m     \u001b[38;5;66;03m# The value of ordered is irrelevant since we don't use cat as such,\u001b[39;00m\n\u001b[1;32m   2994\u001b[0m     \u001b[38;5;66;03m# but only the resulting categories, the order of which is independent\u001b[39;00m\n\u001b[1;32m   2995\u001b[0m     \u001b[38;5;66;03m# from ordered. Set ordered to False as default. See GH #15457\u001b[39;00m\n\u001b[0;32m-> 2996\u001b[0m     cat \u001b[38;5;241m=\u001b[39m Categorical(values, ordered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2997\u001b[0m     categories \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcategories\n\u001b[1;32m   2998\u001b[0m     codes \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mcodes\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:449\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    447\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(values, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 449\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    451\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[1;32m    796\u001b[0m         values,\n\u001b[1;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[1;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[1;32m    799\u001b[0m     )\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    803\u001b[0m         uniques,\n\u001b[1;32m    804\u001b[0m         codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    808\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[1;32m    596\u001b[0m     values,\n\u001b[1;32m    597\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    598\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[1;32m    599\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    600\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[1;32m    601\u001b[0m )\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    data['delta'] = np.log(data['w_old'])\n",
    "    data = sim_shares(data,0,1)\n",
    "    data['w_new'] = data['w_old']*data['s0']/data['tot']\n",
    "    print((np.log(data['w_new'])-np.log(data['w_old'])).abs().mean())\n",
    "    print((data['s0']/data['tot']).mean())\n",
    "    if (np.log(data['w_new'])-np.log(data['w_old'])).abs().mean() < 0.1:\n",
    "            break\n",
    "    data['w_old'] = data['w_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9c860fab-b643-41c1-bc1f-6c62fa595491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>brand_2</th>\n",
       "      <th>brand_3</th>\n",
       "      <th>brand_4</th>\n",
       "      <th>brand_5</th>\n",
       "      <th>...</th>\n",
       "      <th>hhincome17</th>\n",
       "      <th>hhincome18</th>\n",
       "      <th>hhincome19</th>\n",
       "      <th>hhincome20</th>\n",
       "      <th>delta</th>\n",
       "      <th>w_old</th>\n",
       "      <th>w_new</th>\n",
       "      <th>s0</th>\n",
       "      <th>count</th>\n",
       "      <th>tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.475980</td>\n",
       "      <td>11.31761</td>\n",
       "      <td>10.95628</td>\n",
       "      <td>10.73356</td>\n",
       "      <td>-8.160519</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>14181</td>\n",
       "      <td>0.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.476680</td>\n",
       "      <td>11.32159</td>\n",
       "      <td>10.28266</td>\n",
       "      <td>10.02471</td>\n",
       "      <td>-8.731163</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>13965</td>\n",
       "      <td>0.067198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.590904</td>\n",
       "      <td>11.96942</td>\n",
       "      <td>11.36072</td>\n",
       "      <td>11.35747</td>\n",
       "      <td>-10.129091</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>13538</td>\n",
       "      <td>0.069380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.675790</td>\n",
       "      <td>12.48191</td>\n",
       "      <td>10.79339</td>\n",
       "      <td>11.42795</td>\n",
       "      <td>-8.753028</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>13735</td>\n",
       "      <td>0.069164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.067370</td>\n",
       "      <td>11.89204</td>\n",
       "      <td>10.28755</td>\n",
       "      <td>11.68925</td>\n",
       "      <td>-9.096025</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>13735</td>\n",
       "      <td>0.068305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  price_  prom_  brand_2  brand_3  brand_4  \\\n",
       "0      2     1      1      16    3.29    0.0        0        0        0   \n",
       "1      2     2      1      12    3.27    0.0        0        0        0   \n",
       "2      2     3      1       6    3.37    0.0        0        0        0   \n",
       "3      2     4      1      12    3.30    0.0        0        0        0   \n",
       "4      2     5      1      10    3.34    0.0        0        0        0   \n",
       "\n",
       "   brand_5  ...  hhincome17  hhincome18  hhincome19  hhincome20      delta  \\\n",
       "0        0  ...   10.475980    11.31761    10.95628    10.73356  -8.160519   \n",
       "1        0  ...    8.476680    11.32159    10.28266    10.02471  -8.731163   \n",
       "2        0  ...    9.590904    11.96942    11.36072    11.35747 -10.129091   \n",
       "3        0  ...   11.675790    12.48191    10.79339    11.42795  -8.753028   \n",
       "4        0  ...   11.067370    11.89204    10.28755    11.68925  -9.096025   \n",
       "\n",
       "      w_old     w_new        s0  count       tot  \n",
       "0  0.000286  0.000286  0.001128  14181  0.066600  \n",
       "1  0.000161  0.000161  0.000859  13965  0.067198  \n",
       "2  0.000040  0.000040  0.000443  13538  0.069380  \n",
       "3  0.000158  0.000158  0.000874  13735  0.069164  \n",
       "4  0.000112  0.000112  0.000728  13735  0.068305  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00642da7-1fa8-43b9-84bf-d41d9f7e530f",
   "metadata": {},
   "source": [
    "## Step 3: Define GMM objective function\n",
    "\n",
    "We now use our instruments to define an objective function which is to be minimized to find our optimal paramters $\\beta$, $\\sigma_{B}$, and $\\sigma_{I}$. Using the formula found in Nevo's RA guide, we can express $\\beta$ as a function of $(\\sigma_{B},\\sigma_{I})$: \n",
    "$$\\beta = (X^{T}ZWZ^{T}X)^{-1}X^{T}ZWZ^{T}\\delta(\\sigma_{B},\\sigma_{I})$$  \n",
    "With $\\beta$ in hand, we can now calculate $\\xi(\\sigma_{B},\\sigma_{I},\\beta)$ and thus our entire objective function:\n",
    "$$\\xi^{T}ZWZ^{T}\\xi$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "85ea135d-4ca7-42d9-b493-614237ee3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "instr = pd.read_csv('./PS1_Data/OTCDataInstruments.csv',sep='\\t')\n",
    "instr = instr.drop(columns=['store','week','brand','avoutprice'])\n",
    "Z = instr.to_numpy()\n",
    "W = np.linalg.inv(np.matmul(np.transpose(Z),Z))\n",
    "X = orig[['price_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11']].to_numpy()\n",
    "\n",
    "def gmm_obj(sigma):\n",
    "    sigma_B = sigma[0]\n",
    "    sigma_I = sigma[1]\n",
    "    proj = np.linalg.inv(np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),X)))))\n",
    "    vect = np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),calc_delta(data,sigma_B,sigma_I)))))\n",
    "    beta = np.matmul(proj,vect)\n",
    "    xi = calc_xi(data,sigma_B,sigma_I,beta)\n",
    "    ans = np.matmul(np.transpose(xi),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),xi))))\n",
    "    first_comp = np.array([1,0])\n",
    "    second_comp = np.array([0,1])\n",
    "    return [np.matmul(first_comp,ans),np.matmul(second_comp,ans)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9278fee-ccf7-4b69-a168-5ba6dd071f6c",
   "metadata": {},
   "source": [
    "## Step 4: Nonlinear search over parameters\n",
    "\n",
    "Now that we've defined a loss function to minimize, we look for parameters $\\sigma_{B}, \\sigma_{I}$ that minimize it. We use scipy's fsolve, which relies on MINPACK's hybrid algorithm, for nonlinear optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f01aeb-2e1a-40f8-94be-71204e437dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "(sigma_B,sigma_I) = fsolve(gmm_obj,[1,1])\n",
    "proj = np.linalg.inv(np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),X)))))\n",
    "vect = np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),calc_delta(data,sigma_B,sigma_I)))))\n",
    "beta = np.matmul(proj,vect)\n",
    "alpha = beta[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b15ef-0570-4bba-bd20-42c371ab137d",
   "metadata": {},
   "source": [
    "## Elasticity calculation\n",
    "\n",
    "Unlike the logit specification, elasticities under BLP need to be simulated. We will simulate: \n",
    "$$ e_{jjt} = -\\frac{p_{jt}}{s_{jt}}\\int (\\alpha + \\sigma_{I}I_{i})Pr_{ijt}(1-Pr_{ijt})dP_{D}(D)dP_{\\nu}(\\nu) $$ $$ e_{jkt} = \\frac{p_{kt}}{s_{jt}} \\int (\\alpha + \\sigma_{I}I_{i})Pr_{ijt}Pr_{ikt}dP_{D}(D)dP_{\\nu}(\\nu)$$\n",
    "where $Pr_{ijt}$ is the probability of $i$ choosing $j$, simulated using the procedure in step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14efd9-e514-4883-a0c0-aede5976b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delta for each jt-pair\n",
    "data['delta'] = calc_delta(data,sigma_B,sigma_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559faaa-43ee-4b0d-b89c-405a4f3421c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_own_e(orig,alpha,sigma_B,sigma_I):\n",
    "\n",
    "    # e_own is total of all simulated share-price derivatives\n",
    "    orig['e_own'] = 0\n",
    "\n",
    "    # Simulate draws\n",
    "    for i in range(R):\n",
    "        data_copy = master.copy()\n",
    "        \n",
    "        # Demand shock\n",
    "        nu = np.random.normal()\n",
    "        # Choose income randomly\n",
    "        hh = random.randint(1,20)\n",
    "        \n",
    "        data_copy['V'] = data_copy.apply(calc_V,axis=1,args=(sigma_B,sigma_I,nu,hh))\n",
    "\n",
    "        # Use logit to calculate product shares in market\n",
    "        data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "        data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "        data_sum['sum'] = data_sum['sum'] + 1\n",
    "        data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        data_copy['s'] = data_copy['V']/data_copy['sum']\n",
    "        data_copy['dsdp'] = data_copy['s']*(1-data_copy['s'])*(alpha + sigma_I*data_copy['hhincome'+str(hh)])\n",
    "        data_copy = data_copy[['store','week','brand','dsdp']]\n",
    "\n",
    "        # Add this iteration to our total\n",
    "        orig = pd.merge(orig,data_copy,how='left',left_on=['store','week','brand'],right_on=['store','week','brand'],validate='1:1')\n",
    "        orig['e_own'] = orig['e_own'] + orig['dsdp']\n",
    "        orig = orig.drop(columns=['dsdp'])\n",
    "\n",
    "    # Calculate elasticity\n",
    "    orig['e_own'] = -1*orig['price_']*orig['e_own']/R\n",
    "    orig['e_own'] = orig['e_own']*orig['sales_']/orig['count']\n",
    "    return orig\n",
    "\n",
    "\n",
    "def calc_cross_e(orig,alpha,sigma_I,k):\n",
    "\n",
    "    orig['e_'+str(k)] = 0\n",
    "    \n",
    "    for i in range(R):\n",
    "        data_copy = orig.copy()\n",
    "        \n",
    "        # Demand shock\n",
    "        nu = np.random.normal()\n",
    "        # Choose income randomly\n",
    "        hh = random.randint(1,20)\n",
    "\n",
    "        # Calculate utility\n",
    "        data_copy['V'] = data_copy.apply(calc_V,axis=1,args=(sigma_B,sigma_I,nu,hh))\n",
    "\n",
    "        # Use logit to calculate product shares in market\n",
    "        data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "        data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "        data_sum['sum'] = data_sum['sum'] + 1\n",
    "        data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        data_copy['s'] = data_copy['V']/data_copy['sum']\n",
    "\n",
    "        data_k = orig[orig['brand']==k]\n",
    "        data_k = data_k.rename(columns={'s':'s_k'})\n",
    "        data_k = data_k[['store','week','brand','s_k']]\n",
    "        data_copy = pd.merge(data_copy,data_k,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        \n",
    "        data_copy['dsdp'] = data_copy['s']*(data_copy['s_k'])*(alpha + sigma_I*data_copy['hhincome'+str(hh)])\n",
    "        data_copy = data_copy[['store','week','brand','dsdp']]\n",
    "\n",
    "        # Add this iteration to our total\n",
    "        orig = pd.merge(orig,data_copy,how='left',left_on=['store','week','brand'],right_on=['store','week','brand'],validate='1:1')\n",
    "        orig['e_'+str(k)] = orig['e_'+str(k)] + orig['dsdp']\n",
    "        orig = orig.drop(columns=['dsdp'])\n",
    "\n",
    "    data_k = orig[orig['brand']==k]\n",
    "    data_k = data_k.rename(columns={'price_':'price_k'})\n",
    "    data_k = data_k[['store','week','price_k']]\n",
    "    orig = pd.merge(orig,data_k,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "    orig['e_'+str(k)] = orig['e_'+str(k)]*orig['price_k']*orig['sales_']/(orig['count']*R)\n",
    "    \n",
    "    return orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6791fe-77f5-4b50-ac85-23b3a2df1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b: Elasticities for store 9, week 10\n",
    "data = calc_own_e(data,alpha,sigma_B,sigma_I)\n",
    "for i in range(1,12):\n",
    "    data = calc_cross_e(data,alpha,sigma_I,i)\n",
    "\n",
    "data_ans = data[((data['week'] == 10) & (data['store'] == 9))]\n",
    "data_ans = data_ans[['brand','e_own','e_1','e_2','e_3','e_4','e_5','e_6','e_7','e_8','e_9','e_10','e_11']]\n",
    "for i in range(1,12):\n",
    "    data[data['brand']==i]['e_'+str(i)] = data['e_own']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65698bce-48c1-49b1-8a61-aae0758ba9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
