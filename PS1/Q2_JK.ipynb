{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55301984-86bc-4613-9e60-e3eaae93d857",
   "metadata": {},
   "source": [
    "# Question 2 (BLP)\n",
    "\n",
    "We assume the demand model $$u_{ijt} = X_{jt}\\beta + \\sigma_{B}\\nu_{i} + \\alpha p_{jt} + \\sigma_{I}I_{i}p_{jt} + \\xi_{jt} + \\epsilon_{ijt}$$ and use BLP to estimate it. The steps are detailed below:\n",
    "\n",
    "## Step 1: Simulate draws\n",
    "\n",
    "The logit specification of our model implies that our shares can be written as an integral of fractions of utility components. Specifically, we can adapt the formulas from class to our model: $$s_{jt} = \\int \\frac{X_{jt}\\beta + \\sigma_{B}\\nu_{i} + \\alpha p_{jt} + \\sigma_{I}I_{it}p_{jt} + \\xi_{jt}}{1+\\sum_{m=1}^{J}X_{mt}\\beta + \\sigma_{B}\\nu_{i} + \\alpha p_{mt} + \\sigma_{I}I_{it}p_{mt} + \\xi_{mt}}dP_{I}(I)dP_{\\nu}(\\nu)$$ \n",
    "While this integral cannot be solved analytically, we can simulate random draws of income (uniformly over the income data we have for each product-market) and normal demand shocks to estimate shares conditional on demand parameters:\n",
    "$$\\hat{s}_{jt} = \\sum_{r}\\frac{X_{jt}\\beta + \\sigma_{B}\\nu_{r} + \\alpha p_{jt} + \\sigma_{I}I_{rt}p_{jt} + \\xi_{jt}}{1+\\sum_{m=1}^{J}X_{mt}\\beta + \\sigma_{B}\\nu_{r} + \\alpha p_{mt} + \\sigma_{I}I_{rt}p_{mt} + \\xi_{mt}}$$\n",
    "We code a function that returns this share while taking demand parameters as input below.\n",
    "\n",
    "To get closer to the notation used in the lecture notes ($\\beta$ is used differently in the problem set,) we will express the deterministic component of utility as $\\delta_{jt}$ = $X_{jt}\\beta + \\alpha p_{jt} + \\xi_{jt}$ and the variables that interact with the idiosyncratic components as $\\sigma = (\\sigma_{B},\\sigma_{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902fa90f-8c37-4b51-8c44-174554698bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>rev</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>hhincome11</th>\n",
       "      <th>hhincome12</th>\n",
       "      <th>hhincome13</th>\n",
       "      <th>hhincome14</th>\n",
       "      <th>hhincome15</th>\n",
       "      <th>hhincome16</th>\n",
       "      <th>hhincome17</th>\n",
       "      <th>hhincome18</th>\n",
       "      <th>hhincome19</th>\n",
       "      <th>hhincome20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>52.64</td>\n",
       "      <td>32.96</td>\n",
       "      <td>...</td>\n",
       "      <td>9.629704</td>\n",
       "      <td>12.109250</td>\n",
       "      <td>12.435180</td>\n",
       "      <td>11.096550</td>\n",
       "      <td>9.074136</td>\n",
       "      <td>11.56383</td>\n",
       "      <td>10.475980</td>\n",
       "      <td>11.31761</td>\n",
       "      <td>10.95628</td>\n",
       "      <td>10.73356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>39.24</td>\n",
       "      <td>24.48</td>\n",
       "      <td>...</td>\n",
       "      <td>9.627645</td>\n",
       "      <td>9.719968</td>\n",
       "      <td>11.206970</td>\n",
       "      <td>10.461870</td>\n",
       "      <td>10.513160</td>\n",
       "      <td>11.65730</td>\n",
       "      <td>8.476680</td>\n",
       "      <td>11.32159</td>\n",
       "      <td>10.28266</td>\n",
       "      <td>10.02471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>20.22</td>\n",
       "      <td>12.90</td>\n",
       "      <td>...</td>\n",
       "      <td>10.185430</td>\n",
       "      <td>10.272690</td>\n",
       "      <td>10.556770</td>\n",
       "      <td>8.676463</td>\n",
       "      <td>10.341440</td>\n",
       "      <td>11.64640</td>\n",
       "      <td>9.590904</td>\n",
       "      <td>11.96942</td>\n",
       "      <td>11.36072</td>\n",
       "      <td>11.35747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>39.60</td>\n",
       "      <td>24.84</td>\n",
       "      <td>...</td>\n",
       "      <td>11.982770</td>\n",
       "      <td>8.499218</td>\n",
       "      <td>8.030489</td>\n",
       "      <td>11.080500</td>\n",
       "      <td>8.894314</td>\n",
       "      <td>10.27435</td>\n",
       "      <td>11.675790</td>\n",
       "      <td>12.48191</td>\n",
       "      <td>10.79339</td>\n",
       "      <td>11.42795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>33.40</td>\n",
       "      <td>21.20</td>\n",
       "      <td>...</td>\n",
       "      <td>9.367624</td>\n",
       "      <td>9.109353</td>\n",
       "      <td>10.237140</td>\n",
       "      <td>11.982330</td>\n",
       "      <td>10.211610</td>\n",
       "      <td>10.33920</td>\n",
       "      <td>11.067370</td>\n",
       "      <td>11.89204</td>\n",
       "      <td>10.28755</td>\n",
       "      <td>11.68925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_    rev  total_cost  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06  52.64       32.96   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04  39.24       24.48   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15  20.22       12.90   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07  39.60       24.84   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12  33.40       21.20   \n",
       "\n",
       "   ...  hhincome11  hhincome12  hhincome13  hhincome14  hhincome15  \\\n",
       "0  ...    9.629704   12.109250   12.435180   11.096550    9.074136   \n",
       "1  ...    9.627645    9.719968   11.206970   10.461870   10.513160   \n",
       "2  ...   10.185430   10.272690   10.556770    8.676463   10.341440   \n",
       "3  ...   11.982770    8.499218    8.030489   11.080500    8.894314   \n",
       "4  ...    9.367624    9.109353   10.237140   11.982330   10.211610   \n",
       "\n",
       "   hhincome16  hhincome17  hhincome18  hhincome19  hhincome20  \n",
       "0    11.56383   10.475980    11.31761    10.95628    10.73356  \n",
       "1    11.65730    8.476680    11.32159    10.28266    10.02471  \n",
       "2    11.64640    9.590904    11.96942    11.36072    11.35747  \n",
       "3    10.27435   11.675790    12.48191    10.79339    11.42795  \n",
       "4    10.33920   11.067370    11.89204    10.28755    11.68925  \n",
       "\n",
       "[5 rows x 849 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('./cleaned_data/data.csv')\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "\n",
    "demo = pd.read_csv('./PS1_Data/OTCDemographics.csv',sep='\\t')\n",
    "data = pd.merge(data,demo,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607eb459-80b8-49d3-92bc-9f5ace778f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "R = 100\n",
    "\n",
    "# Simulate an individual draw in a single market: each row is a jt-level entry\n",
    "# Assumes delta is already calculated\n",
    "# def calc_V(row,sigma_B,sigma_I,nu,hh):\n",
    "    \n",
    "#     return row['delta'] + sigma_B*nu + sigma_I*row['hhincome'+str(hh)]*row['price_']\n",
    "\n",
    "\n",
    "# Simulate draws R=100 times and average out shares\n",
    "# def sim_shares(orig,sigma_B,sigma_I):\n",
    "\n",
    "#     # Keep covariates and intermediate variables\n",
    "#     master = orig[['store','week','brand','sales_','price_','prom_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11','hhincome1','hhincome2','hhincome3','hhincome4','hhincome5','hhincome6','hhincome7','hhincome8','hhincome9','hhincome10','hhincome11','hhincome12','hhincome13','hhincome14','hhincome15','hhincome16','hhincome17','hhincome18','hhincome19','hhincome20','delta','w_old','w_new','s0','count']]\n",
    "#     # tot is total of all simulated shares\n",
    "#     master['tot'] = 0\n",
    "\n",
    "#     # Simulate draws\n",
    "#     for i in range(R):\n",
    "#         data_copy = master.copy()\n",
    "        \n",
    "#         # Demand shock\n",
    "#         nu = np.random.normal()\n",
    "#         # Choose income randomly\n",
    "#         hh = random.randint(1,20)\n",
    "        \n",
    "#         # data_copy['V'] = data_copy.apply(calc_V,axis=1,args=(sigma_B,sigma_I,nu,hh))\n",
    "#         data_copy['V'] = data_copy['delta'] + sigma_B*nu + sigma_I*data_copy['hhincome'+str(hh)]*data_copy['price_']\n",
    "        \n",
    "#         # Use logit to calculate product shares in market\n",
    "#         data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "#         data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "#         data_sum['sum'] = data_sum['sum'] + 1\n",
    "#         data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "#         data_copy['s'] = data_copy['V']/data_copy['sum']\n",
    "#         data_copy = data_copy[['store','week','brand','s']]\n",
    "\n",
    "#         # Add this iteration to our total\n",
    "#         master = pd.merge(master,data_copy,how='left',left_on=['store','week','brand'],right_on=['store','week','brand'],validate='1:1')\n",
    "#         master['tot'] = master['tot'] + master['s']\n",
    "#         master = master.drop(columns=['s'])\n",
    "\n",
    "#     # Average share\n",
    "#     master['tot'] = master['tot']/R\n",
    "#     return master\n",
    "def sim_shares(master,sigma_B,sigma_I):\n",
    "\n",
    "    # Keep covariates and intermediate variables\n",
    "    master = master[['store','week','brand','ms_by_store_week','sales_','price_','prom_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11','hhincome1','hhincome2','hhincome3','hhincome4','hhincome5','hhincome6','hhincome7','hhincome8','hhincome9','hhincome10','hhincome11','hhincome12','hhincome13','hhincome14','hhincome15','hhincome16','hhincome17','hhincome18','hhincome19','hhincome20','w_old','w_new','count']]\n",
    "    \n",
    "    # tot is total of all simulated shares\n",
    "    # master['tot'] = 0\n",
    "    total = pd.Series([0 for _ in range(len(master))])\n",
    "    \n",
    "    nus = np.random.standard_normal(R)\n",
    "    # Simulate draws\n",
    "    for i in range(R):\n",
    "        data_copy = master.copy()\n",
    "        # Demand shock\n",
    "        nu = nus[i]\n",
    "        # Choose income randomly\n",
    "        hh = random.randint(1,20)\n",
    "\n",
    "        data_copy['V'] = data_copy['w_old']*np.exp(sigma_B*nu + sigma_I*data_copy[f'hhincome{hh}']*data_copy['price_'])\n",
    "        # Use logit to calculate product shares in market\n",
    "        data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "        data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "        data_sum['sum'] = data_sum['sum'] + 1\n",
    "        data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        s = data_copy['V']/data_copy['sum']\n",
    "        total += s\n",
    "\n",
    "    # Average share\n",
    "    master['est'] = total/R\n",
    "    return master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d9bb2-00cc-47bd-abb8-cafbfa77eca8",
   "metadata": {},
   "source": [
    "## Step 2: Contraction Mapping\n",
    "\n",
    "Given $sigma_{B}, sigma_{I}$, we can iterate the contraction mapping in the lecture notes to approximate a value of $\\delta_{jt}$ for each product-market pair that results in a share close to the actual shares in the data. The equation we iterate to approximate $\\delta_{jt}$ is:\n",
    "$$\\exp(\\delta^{i+1}_{jt}) = \\exp(\\delta^{i}_{jt})\\frac{s_{jt}^{0}}{s_{jt}(\\delta^{i}_{jt},\\beta)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b33e505-8fe5-45d9-9f48-eb4d5c9d7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate actual shares in data to use in iteration\n",
    "# def calc_initial_shares(orig):\n",
    "\n",
    "#     # Sum sales\n",
    "#     data_sum = orig.groupby(['store', 'week'],as_index=False)['sales_'].sum()\n",
    "#     data_sum.rename(columns={'sales_':'sum'},inplace=True)\n",
    "\n",
    "#     # Calculate initial shares\n",
    "#     orig = pd.merge(orig,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "#     orig['s0'] = orig['sales_']/orig['count']\n",
    "#     orig['share0'] = 1 - (orig['sum']/orig['count'])\n",
    "#     orig['init'] = np.log(orig['s0']/orig['share0'])\n",
    "#     orig = orig.drop(columns=['sum','share0'])\n",
    "#     return orig   \n",
    "\n",
    "\n",
    "# Calculate delta: deterministic component of jt-level utility\n",
    "# def calc_delta(orig,sigma_B,sigma_I):\n",
    "    \n",
    "#     # Calculate initial shares\n",
    "#     orig = calc_initial_shares(orig)\n",
    "\n",
    "#     # Initialize search values and threshold\n",
    "#     epsilon = 0.1\n",
    "#     orig['w_old'] = np.exp(orig['s0'])\n",
    "#     orig['w_new'] = 0\n",
    "#     count = 0\n",
    "\n",
    "#     # Iterate contraction mapping until threshold is found\n",
    "#     while True:\n",
    "#         orig['delta'] = np.log(orig['w_old'])\n",
    "#         orig = sim_shares(orig,sigma_B,sigma_I)\n",
    "#         orig['w_new'] = orig['w_old']*orig['s0']/orig['tot']\n",
    "#         if (np.log(orig['w_new'])-np.log(orig['w_old'])).abs().mean() < epsilon:\n",
    "#             break\n",
    "#         orig['w_old'] = orig['w_new']\n",
    "#         count += 1\n",
    "\n",
    "#     return np.log(orig['w_new']).to_numpy()\n",
    "\n",
    "def calc_delta(orig,sigma_B,sigma_I,delta=None):\n",
    "    # Initialize search values and threshold\n",
    "    epsilon = 0.01\n",
    "    orig['w_old'] = np.exp(delta) if delta is not None else np.exp(orig['ms_by_store_week'])\n",
    "    orig['w_new'] = 0\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate contraction mapping until threshold is found\n",
    "    while True:\n",
    "        if any(orig['w_old'].isnull()):\n",
    "            print(count)\n",
    "            raise Exception(\"NaNs\")\n",
    "\n",
    "        orig = sim_shares(orig,sigma_B,sigma_I)\n",
    "        orig['w_new'] = orig['w_old']*orig['ms_by_store_week']/orig['est']\n",
    "        \n",
    "        if np.average(np.log(orig['ms_by_store_week']/orig['est']).abs()) < epsilon:\n",
    "            break\n",
    "        if count > 100:\n",
    "            print(\"over_count\")\n",
    "            print(np.average(np.log(orig['ms_by_store_week']/orig['est'])))\n",
    "            break\n",
    "        orig['w_old'] = orig['w_new']\n",
    "        count += 1\n",
    "\n",
    "    return np.log(orig['w_new']).to_numpy()\n",
    "\n",
    "# Calculate xi: our jt-level residual\n",
    "# Two parts: iterate contraction mapping, then subtract out linear terms given beta\n",
    "def calc_xi(orig,sigma_B,sigma_I,beta):\n",
    "\n",
    "    # Calculate delta\n",
    "    orig['delta'] = calc_delta(orig,sigma_B,sigma_I)    \n",
    "\n",
    "    # Calculate xi: take linear component out of delta\n",
    "    orig['xi'] = orig['delta'] - orig[['price_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11']].dot(beta)\n",
    "    return orig['xi'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c7330-4fd0-488d-8921-9ff8bf654ac0",
   "metadata": {},
   "source": [
    "Below I try to run the above code step by step. Keeping the mess so that you can see the (lack of) convergence: the outputted numbers are the difference between successive values of $\\delta_{jt}$, averaged over all jt-pairs. It looks like there's initial convergence, but eventually it starts to explode..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7129ec-8d12-4ca8-80b2-6fd8cc41bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l2/qgb9rd795r92jzsy94cy01080000gn/T/ipykernel_36814/998985169.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  master['tot'] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.489137223491835\n"
     ]
    }
   ],
   "source": [
    "beta = np.zeros(11)\n",
    "beta[0] = 1\n",
    "data = calc_initial_shares(data)\n",
    "epsilon = 0.1\n",
    "data['w_old'] = np.exp(data['s0'])\n",
    "data['w_new'] = 0\n",
    "\n",
    "data['delta'] = np.log(data['w_old'])\n",
    "data = sim_shares(data,1,1)\n",
    "data['w_new'] = data['w_old']*data['s0']/data['tot']\n",
    "print((np.log(data['w_new'])-np.log(data['w_old'])).abs().mean())\n",
    "data['w_old'] = data['w_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90bcac83-943d-4e8a-b7c6-11479516f702",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'w_old'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'w_old'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_old\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m sim_shares(data,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_old\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'w_old'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    data['delta'] = np.log(data['w_old'])\n",
    "    data = sim_shares(data,0,1)\n",
    "    data['w_new'] = data['w_old']*data['s0']/data['tot']\n",
    "    print((np.log(data['w_new'])-np.log(data['w_old'])).abs().mean())\n",
    "    print((data['s0']/data['tot']).mean())\n",
    "    if (np.log(data['w_new'])-np.log(data['w_old'])).abs().mean() < 0.1:\n",
    "            break\n",
    "    data['w_old'] = data['w_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9c860fab-b643-41c1-bc1f-6c62fa595491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>brand_2</th>\n",
       "      <th>brand_3</th>\n",
       "      <th>brand_4</th>\n",
       "      <th>brand_5</th>\n",
       "      <th>...</th>\n",
       "      <th>hhincome17</th>\n",
       "      <th>hhincome18</th>\n",
       "      <th>hhincome19</th>\n",
       "      <th>hhincome20</th>\n",
       "      <th>delta</th>\n",
       "      <th>w_old</th>\n",
       "      <th>w_new</th>\n",
       "      <th>s0</th>\n",
       "      <th>count</th>\n",
       "      <th>tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.475980</td>\n",
       "      <td>11.31761</td>\n",
       "      <td>10.95628</td>\n",
       "      <td>10.73356</td>\n",
       "      <td>-8.160519</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>14181</td>\n",
       "      <td>0.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.476680</td>\n",
       "      <td>11.32159</td>\n",
       "      <td>10.28266</td>\n",
       "      <td>10.02471</td>\n",
       "      <td>-8.731163</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>13965</td>\n",
       "      <td>0.067198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.590904</td>\n",
       "      <td>11.96942</td>\n",
       "      <td>11.36072</td>\n",
       "      <td>11.35747</td>\n",
       "      <td>-10.129091</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>13538</td>\n",
       "      <td>0.069380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.675790</td>\n",
       "      <td>12.48191</td>\n",
       "      <td>10.79339</td>\n",
       "      <td>11.42795</td>\n",
       "      <td>-8.753028</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>13735</td>\n",
       "      <td>0.069164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.067370</td>\n",
       "      <td>11.89204</td>\n",
       "      <td>10.28755</td>\n",
       "      <td>11.68925</td>\n",
       "      <td>-9.096025</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>13735</td>\n",
       "      <td>0.068305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  price_  prom_  brand_2  brand_3  brand_4  \\\n",
       "0      2     1      1      16    3.29    0.0        0        0        0   \n",
       "1      2     2      1      12    3.27    0.0        0        0        0   \n",
       "2      2     3      1       6    3.37    0.0        0        0        0   \n",
       "3      2     4      1      12    3.30    0.0        0        0        0   \n",
       "4      2     5      1      10    3.34    0.0        0        0        0   \n",
       "\n",
       "   brand_5  ...  hhincome17  hhincome18  hhincome19  hhincome20      delta  \\\n",
       "0        0  ...   10.475980    11.31761    10.95628    10.73356  -8.160519   \n",
       "1        0  ...    8.476680    11.32159    10.28266    10.02471  -8.731163   \n",
       "2        0  ...    9.590904    11.96942    11.36072    11.35747 -10.129091   \n",
       "3        0  ...   11.675790    12.48191    10.79339    11.42795  -8.753028   \n",
       "4        0  ...   11.067370    11.89204    10.28755    11.68925  -9.096025   \n",
       "\n",
       "      w_old     w_new        s0  count       tot  \n",
       "0  0.000286  0.000286  0.001128  14181  0.066600  \n",
       "1  0.000161  0.000161  0.000859  13965  0.067198  \n",
       "2  0.000040  0.000040  0.000443  13538  0.069380  \n",
       "3  0.000158  0.000158  0.000874  13735  0.069164  \n",
       "4  0.000112  0.000112  0.000728  13735  0.068305  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00642da7-1fa8-43b9-84bf-d41d9f7e530f",
   "metadata": {},
   "source": [
    "## Step 3: Define GMM objective function\n",
    "\n",
    "We now use our instruments to define an objective function which is to be minimized to find our optimal paramters $\\beta$, $\\sigma_{B}$, and $\\sigma_{I}$. Using the formula found in Nevo's RA guide, we can express $\\beta$ as a function of $(\\sigma_{B},\\sigma_{I})$: \n",
    "$$\\beta = (X^{T}ZWZ^{T}X)^{-1}X^{T}ZWZ^{T}\\delta(\\sigma_{B},\\sigma_{I})$$  \n",
    "With $\\beta$ in hand, we can now calculate $\\xi(\\sigma_{B},\\sigma_{I},\\beta)$ and thus our entire objective function:\n",
    "$$\\xi^{T}ZWZ^{T}\\xi$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ea135d-4ca7-42d9-b493-614237ee3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "instr = pd.read_csv('./PS1_Data/OTCDataInstruments.csv',sep='\\t')\n",
    "instr = instr.drop(columns=['store','week','brand','avoutprice'])\n",
    "Z = instr.to_numpy()\n",
    "W = np.linalg.inv(np.matmul(np.transpose(Z),Z))\n",
    "X = data[['price_','brand_2','brand_3','brand_4','brand_5','brand_6','brand_7','brand_8','brand_9','brand_10','brand_11']].to_numpy()\n",
    "\n",
    "def gmm_obj(sigma):\n",
    "    sigma_B = sigma[0]\n",
    "    sigma_I = sigma[1]\n",
    "    print(sigma)\n",
    "    proj = np.linalg.inv(np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),X)))))\n",
    "    vect = np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),calc_delta(data,sigma_B,sigma_I)))))\n",
    "    beta = np.matmul(proj,vect)\n",
    "    xi = calc_xi(data,sigma_B,sigma_I,beta)\n",
    "    ans = np.matmul(np.transpose(xi),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),xi))))\n",
    "    first_comp = np.array([1,0])\n",
    "    second_comp = np.array([0,1])\n",
    "    return [np.matmul(first_comp,ans),np.matmul(second_comp,ans)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9278fee-ccf7-4b69-a168-5ba6dd071f6c",
   "metadata": {},
   "source": [
    "## Step 4: Nonlinear search over parameters\n",
    "\n",
    "Now that we've defined a loss function to minimize, we look for parameters $\\sigma_{B}, \\sigma_{I}$ that minimize it. We use scipy's fsolve, which relies on MINPACK's hybrid algorithm, for nonlinear optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f01aeb-2e1a-40f8-94be-71204e437dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "over_count\n",
      "9.451880841204814e-05\n",
      "over_count\n",
      "0.05007320425449573\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fsolve\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m (sigma_B,sigma_I) \u001b[38;5;241m=\u001b[39m fsolve(gmm_obj,[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m proj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(np\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mtranspose(X),np\u001b[38;5;241m.\u001b[39mmatmul(Z,np\u001b[38;5;241m.\u001b[39mmatmul(W,np\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mtranspose(Z),X)))))\n\u001b[1;32m      6\u001b[0m vect \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mtranspose(X),np\u001b[38;5;241m.\u001b[39mmatmul(Z,np\u001b[38;5;241m.\u001b[39mmatmul(W,np\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mtranspose(Z),calc_delta(data,sigma_B,sigma_I)))))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:162\u001b[0m, in \u001b[0;36mfsolve\u001b[0;34m(func, x0, args, fprime, full_output, col_deriv, xtol, maxfev, band, epsfcn, factor, diag)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mFind the roots of a function.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_deriv\u001b[39m\u001b[38;5;124m'\u001b[39m: col_deriv,\n\u001b[1;32m    155\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxtol\u001b[39m\u001b[38;5;124m'\u001b[39m: xtol,\n\u001b[1;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxfev\u001b[39m\u001b[38;5;124m'\u001b[39m: maxfev,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m'\u001b[39m: factor,\n\u001b[1;32m    160\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m: diag}\n\u001b[0;32m--> 162\u001b[0m res \u001b[38;5;241m=\u001b[39m _root_hybr(func, x0, args, jac\u001b[38;5;241m=\u001b[39mfprime, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    164\u001b[0m     x \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:228\u001b[0m, in \u001b[0;36m_root_hybr\u001b[0;34m(func, x0, args, jac, col_deriv, xtol, maxfev, band, eps, factor, diag, **unknown_options)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    227\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m--> 228\u001b[0m shape, dtype \u001b[38;5;241m=\u001b[39m _check_func(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsolve\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m, func, x0, args, n, (n,))\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epsfcn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     epsfcn \u001b[38;5;241m=\u001b[39m finfo(dtype)\u001b[38;5;241m.\u001b[39meps\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:25\u001b[0m, in \u001b[0;36m_check_func\u001b[0;34m(checker, argname, thefunc, x0, args, numinputs, output_shape)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_func\u001b[39m(checker, argname, thefunc, x0, args, numinputs,\n\u001b[1;32m     24\u001b[0m                 output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m     res \u001b[38;5;241m=\u001b[39m atleast_1d(thefunc(\u001b[38;5;241m*\u001b[39m((x0[:numinputs],) \u001b[38;5;241m+\u001b[39m args)))\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (output_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (shape(res) \u001b[38;5;241m!=\u001b[39m output_shape):\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (output_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mgmm_obj\u001b[0;34m(sigma)\u001b[0m\n\u001b[1;32m     16\u001b[0m first_comp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     17\u001b[0m second_comp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mmatmul(first_comp,ans),np\u001b[38;5;241m.\u001b[39mmatmul(second_comp,ans)]\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "(sigma_B,sigma_I) = fsolve(gmm_obj,[1,1])\n",
    "proj = np.linalg.inv(np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),X)))))\n",
    "vect = np.matmul(np.transpose(X),np.matmul(Z,np.matmul(W,np.matmul(np.transpose(Z),calc_delta(data,sigma_B,sigma_I)))))\n",
    "beta = np.matmul(proj,vect)\n",
    "alpha = beta[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b15ef-0570-4bba-bd20-42c371ab137d",
   "metadata": {},
   "source": [
    "## Elasticity calculation\n",
    "\n",
    "Unlike the logit specification, elasticities under BLP need to be simulated. We will simulate: \n",
    "$$ e_{jjt} = -\\frac{p_{jt}}{s_{jt}}\\int (\\alpha + \\sigma_{I}I_{i})Pr_{ijt}(1-Pr_{ijt})dP_{D}(D)dP_{\\nu}(\\nu) $$ $$ e_{jkt} = \\frac{p_{kt}}{s_{jt}} \\int (\\alpha + \\sigma_{I}I_{i})Pr_{ijt}Pr_{ikt}dP_{D}(D)dP_{\\nu}(\\nu)$$\n",
    "where $Pr_{ijt}$ is the probability of $i$ choosing $j$, simulated using the procedure in step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14efd9-e514-4883-a0c0-aede5976b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delta for each jt-pair\n",
    "data['delta'] = calc_delta(data,sigma_B,sigma_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559faaa-43ee-4b0d-b89c-405a4f3421c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_own_e(orig,alpha,sigma_B,sigma_I):\n",
    "\n",
    "    # e_own is total of all simulated share-price derivatives\n",
    "    orig['e_own'] = 0\n",
    "\n",
    "    # Simulate draws\n",
    "    for i in range(R):\n",
    "        data_copy = master.copy()\n",
    "        \n",
    "        # Demand shock\n",
    "        nu = np.random.normal()\n",
    "        # Choose income randomly\n",
    "        hh = random.randint(1,20)\n",
    "        \n",
    "        data_copy['V'] = data_copy.apply(calc_V,axis=1,args=(sigma_B,sigma_I,nu,hh))\n",
    "\n",
    "        # Use logit to calculate product shares in market\n",
    "        data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "        data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "        data_sum['sum'] = data_sum['sum'] + 1\n",
    "        data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        data_copy['s'] = data_copy['V']/data_copy['sum']\n",
    "        data_copy['dsdp'] = data_copy['s']*(1-data_copy['s'])*(alpha + sigma_I*data_copy['hhincome'+str(hh)])\n",
    "        data_copy = data_copy[['store','week','brand','dsdp']]\n",
    "\n",
    "        # Add this iteration to our total\n",
    "        orig = pd.merge(orig,data_copy,how='left',left_on=['store','week','brand'],right_on=['store','week','brand'],validate='1:1')\n",
    "        orig['e_own'] = orig['e_own'] + orig['dsdp']\n",
    "        orig = orig.drop(columns=['dsdp'])\n",
    "\n",
    "    # Calculate elasticity\n",
    "    orig['e_own'] = -1*orig['price_']*orig['e_own']/R\n",
    "    orig['e_own'] = orig['e_own']*orig['sales_']/orig['count']\n",
    "    return orig\n",
    "\n",
    "\n",
    "def calc_cross_e(orig,alpha,sigma_I,k):\n",
    "\n",
    "    orig['e_'+str(k)] = 0\n",
    "    \n",
    "    for i in range(R):\n",
    "        data_copy = orig.copy()\n",
    "        \n",
    "        # Demand shock\n",
    "        nu = np.random.normal()\n",
    "        # Choose income randomly\n",
    "        hh = random.randint(1,20)\n",
    "\n",
    "        # Calculate utility\n",
    "        data_copy['V'] = data_copy.apply(calc_V,axis=1,args=(sigma_B,sigma_I,nu,hh))\n",
    "\n",
    "        # Use logit to calculate product shares in market\n",
    "        data_sum = data_copy.groupby(['store', 'week'],as_index=False)['V'].sum()\n",
    "        data_sum.rename(columns={'V':'sum'},inplace=True)\n",
    "        data_sum['sum'] = data_sum['sum'] + 1\n",
    "        data_copy = pd.merge(data_copy,data_sum,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        data_copy['s'] = data_copy['V']/data_copy['sum']\n",
    "\n",
    "        data_k = orig[orig['brand']==k]\n",
    "        data_k = data_k.rename(columns={'s':'s_k'})\n",
    "        data_k = data_k[['store','week','brand','s_k']]\n",
    "        data_copy = pd.merge(data_copy,data_k,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "        \n",
    "        data_copy['dsdp'] = data_copy['s']*(data_copy['s_k'])*(alpha + sigma_I*data_copy['hhincome'+str(hh)])\n",
    "        data_copy = data_copy[['store','week','brand','dsdp']]\n",
    "\n",
    "        # Add this iteration to our total\n",
    "        orig = pd.merge(orig,data_copy,how='left',left_on=['store','week','brand'],right_on=['store','week','brand'],validate='1:1')\n",
    "        orig['e_'+str(k)] = orig['e_'+str(k)] + orig['dsdp']\n",
    "        orig = orig.drop(columns=['dsdp'])\n",
    "\n",
    "    data_k = orig[orig['brand']==k]\n",
    "    data_k = data_k.rename(columns={'price_':'price_k'})\n",
    "    data_k = data_k[['store','week','price_k']]\n",
    "    orig = pd.merge(orig,data_k,how='left',left_on=['store','week'],right_on=['store','week'],validate='m:1')\n",
    "    orig['e_'+str(k)] = orig['e_'+str(k)]*orig['price_k']*orig['sales_']/(orig['count']*R)\n",
    "    \n",
    "    return orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6791fe-77f5-4b50-ac85-23b3a2df1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b: Elasticities for store 9, week 10\n",
    "data = calc_own_e(data,alpha,sigma_B,sigma_I)\n",
    "for i in range(1,12):\n",
    "    data = calc_cross_e(data,alpha,sigma_I,i)\n",
    "\n",
    "data_ans = data[((data['week'] == 10) & (data['store'] == 9))]\n",
    "data_ans = data_ans[['brand','e_own','e_1','e_2','e_3','e_4','e_5','e_6','e_7','e_8','e_9','e_10','e_11']]\n",
    "for i in range(1,12):\n",
    "    data[data['brand']==i]['e_'+str(i)] = data['e_own']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65698bce-48c1-49b1-8a61-aae0758ba9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
